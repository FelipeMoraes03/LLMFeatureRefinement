{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "gemini_api_key = os.getenv(\"GEMINI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = genai.Client(api_key=gemini_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Root Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # All root features\n",
    "# with open(\"../data/root_features.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "#     root_features = json.load(file)\n",
    "\n",
    "# Selected root features\n",
    "with open(\"../data/selected_features.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    root_features = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\"\n",
    "\"You are an expert in mobile app development and requirements engineering. \n",
    "You excel at decomposing high-level features into detailed sub-features.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_level1_prompt(feature: str, feature_description: str, num_features: int = 5) -> str:\n",
    "    return f\"\"\"\n",
    "**Feature**\n",
    "```\n",
    "{feature}: {feature_description}\n",
    "```\n",
    "Given the mobile app feature above, please refine it to a list of sub-features.\n",
    "Ensure that the number of sub-features is {num_features}.\n",
    "The output should be a list of JSON formatted objects like this:\n",
    "[{{\n",
    "\"sub_feature\": sub_feature,\n",
    "\"description\": description\n",
    "}}]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_level2_prompt(feature: str, feature_description: str, super_feature: str, super_feature_description:str, \n",
    "                      siblings_features: List[str], num_features: int = 5) -> str:\n",
    "    return f\"\"\"\n",
    "**Super Feature**\n",
    "```\n",
    "super-feature: {super_feature}\n",
    "description: {super_feature_description}\n",
    "```\n",
    "Knowing that the feature \"{super_feature}\" above is refined into a list of the following features:\n",
    "```\n",
    "{siblings_features}\n",
    "```\n",
    "\n",
    "Please refine the following to a list of sub-features.\n",
    "Ensure that the number of sub-features is {num_features}.\n",
    "\n",
    "**Feature**\n",
    "```\n",
    "feature: {feature}\n",
    "description: {feature_description}\n",
    "```\n",
    "\n",
    "The output should be a list of JSON formatted objects like this:\n",
    "[\n",
    "    {{\n",
    "        \"sub_feature\": sub_feature,\n",
    "        \"description\": description\n",
    "    }}\n",
    "]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Level 1 Feature Refinements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_level_results = []\n",
    "\n",
    "for feature in root_features:\n",
    "    prompt = get_level1_prompt(\n",
    "        feature[\"feature\"],\n",
    "        feature[\"description\"]\n",
    "    )\n",
    "\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.0-flash\",\n",
    "        config=types.GenerateContentConfig(system_instruction=system_prompt),\n",
    "        contents=prompt\n",
    "    )\n",
    "\n",
    "    first_level_results.append({\n",
    "        \"feature\": feature[\"feature\"],\n",
    "        \"description\": feature[\"description\"],\n",
    "        \"sub_features\": json.loads((response.text).replace('```', '').replace('json', ''))\n",
    "    })\n",
    "\n",
    "    # Minimizar problemas de limite de requisicao por minuto\n",
    "    time.sleep(5)\n",
    "\n",
    "# Salvar os resultados em um arquivo JSON\n",
    "with open(\"../data/gemini/base_prompt/first_level_subfeatures.json\", \"w\") as f:\n",
    "    json.dump(first_level_results, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Level 2 Feature Refinements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_level_results = []\n",
    "\n",
    "for super_feature in first_level_results:\n",
    "    for feature in super_feature[\"sub_features\"]:\n",
    "        prompt = get_level2_prompt(\n",
    "            feature[\"sub_feature\"], \n",
    "            feature[\"description\"],\n",
    "            super_feature[\"feature\"],\n",
    "            super_feature[\"description\"],\n",
    "            [f[\"sub_feature\"] for f in super_feature[\"sub_features\"]]\n",
    "        )\n",
    "\n",
    "        response = client.models.generate_content(\n",
    "            model=\"gemini-2.0-flash\",\n",
    "            config=types.GenerateContentConfig(system_instruction=system_prompt),\n",
    "            contents=prompt\n",
    "        )\n",
    "\n",
    "        second_level_results.append({\n",
    "            \"super_feature\": super_feature[\"feature\"],\n",
    "            \"super_feature_description\": super_feature[\"description\"],\n",
    "            \"feature\": feature[\"sub_feature\"],\n",
    "            \"description\": feature[\"description\"],\n",
    "            \"siblings\": [f[\"sub_feature\"] for f in super_feature[\"sub_features\"]],\n",
    "            \"sub_features\": json.loads((response.text).replace('```', '').replace('json', ''))\n",
    "        })\n",
    "\n",
    "        # Minimizar problemas de limite de requisicao por minuto\n",
    "        time.sleep(5)\n",
    "\n",
    "# Salvar os resultados em um arquivo JSON\n",
    "with open(\"../data/gemini/base_prompt/second_level_subfeatures.json\", \"w\") as f:\n",
    "    json.dump(second_level_results, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
