{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "\n",
    "from ollama import chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_technique = 'chain_of_thought'\n",
    "generator_model = 'gemini'\n",
    "evaluator_model = 'deepseek-v2:16b'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"../data/{generator_model}/{prompt_technique}/first_level_subfeatures.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    first_level_subfeatures = json.load(file)\n",
    "\n",
    "with open(f\"../data/{generator_model}/{prompt_technique}/second_level_subfeatures.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    second_level_subfeatures = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"../data/eval_criteria.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    eval_criteria = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are an expert in mobile app development and requirements engineering.  \n",
    "Your primary responsibility is to **critically evaluate** the refinement of software features, ensuring that the breakdown of high-level features into sub-features is **logical, precise, relevant, and technically feasible**.  \n",
    "\n",
    "Your evaluation must adhere **strictly** to the following criteria, applying **a rigorous standard** in your assessment:  \n",
    "\n",
    "### **Evaluation Criteria**\n",
    "\n",
    "1. **Feature Relationship Classification**:\n",
    "   - Classify each sub-feature in relation to the root feature using one of the following:\n",
    "     - **Sub-feature**: A feature that is directly derived from and dependent on the root feature.\n",
    "     - **Sibling feature**: A feature at the same hierarchical level as the root feature.\n",
    "     - **Super feature**: A feature that is broader or encompasses the root feature.\n",
    "     - **Identical feature**: A feature that is essentially the same as the root feature.\n",
    "     - **Other**: A feature that does not fit into the above categories.\n",
    "\n",
    "**Be precise in classification. Misclassification should be flagged.** \n",
    "\n",
    "-----\n",
    "\n",
    "2. **Relevance (Rating: 1 to 5)**:\n",
    "   - Evaluate how relevant the sub-feature is to the root feature:\n",
    "     - 5: Highly relevant and a natural extension.\n",
    "     - 4: Mostly relevant and logically connected.\n",
    "     - 3: Moderately relevant but might not serve the same purpose.\n",
    "     - 2: Somewhat relevant, mainly because it belongs to the same app category.\n",
    "     - 1: Not relevant at all.\n",
    "\n",
    "**A score of 4 or 5 requires a clear justification. A score of 1 or 2 must explain why the sub-feature does not align.**  \n",
    "\n",
    "-----\n",
    "\n",
    "3. **Clarity (Rating: 1 to 5)**:\n",
    "   - Assess the clarity and understandability of the sub-feature description:\n",
    "     - 5: Very clear and easily understandable.\n",
    "     - 4: Mostly clear with minor syntax issues.\n",
    "     - 3: Somewhat clear but contains ambiguities or is too lengthy.\n",
    "     - 2: Mostly unclear and difficult to understand.\n",
    "     - 1: Very unclear or irrelevant.\n",
    "\n",
    "**If the description lacks sufficient detail or is ambiguous, clarity should not exceed 3.**\n",
    "\n",
    "-----\n",
    "\n",
    "4. **Feasibility (Rating: 1 to 5)**:\n",
    "   - Evaluate how practical and implementable the sub-feature is:\n",
    "     - 5: Feasible and commonly implemented in existing apps.\n",
    "     - 4: Feasible but lacks clear real-world examples.\n",
    "     - 3: Probably feasible but has some uncertainties.\n",
    "     - 2: Probably not feasible due to technical limitations.\n",
    "     - 1: Not feasible at all.\n",
    "\n",
    "**If feasibility is uncertain, assume a **cautious** stance. Avoid overestimating feasibility.**\n",
    "\n",
    "-----\n",
    "\n",
    "**Instructions**:\n",
    "- Provide a structured evaluation for each sub-feature.\n",
    "- **Use the exact format** provided below for your response. \n",
    "- **Do not provide justifications** or explanations for the ratings or classifications.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt(feature: str, feature_description: str, super_feature: str, super_feature_description: str,) -> str:\n",
    "    return f\"\"\"\n",
    "Given the following mobile app feature and its refined sub-feature, evaluate the sub-feature based on the provided system guidelines.\n",
    "\n",
    "**Feature**\n",
    "```\n",
    "feature: {super_feature}\n",
    "description: {super_feature_description}\n",
    "```\n",
    "\n",
    "**Sub-feature to Evaluate**\n",
    "```\n",
    "sub_feature: {feature}\n",
    "description: {feature_description}\n",
    "```\n",
    "\n",
    "Provide a structured evaluation of this sub-feature, based on provided criteria.\n",
    "\n",
    "Return the evaluation as a structured JSON object in the following format:\n",
    "{{\n",
    "    \"relationship\": \"Sub-feature | Sibling feature | Super feature | Identical feature | Other\",\n",
    "    \"relevance\": Rating (1-5),\n",
    "    \"clarity\": Rating (1-5),\n",
    "    \"feasibility\": Rating (1-5)\n",
    "}}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Level 1 Feature Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_level_eval = []\n",
    "\n",
    "for super_feature in first_level_subfeatures:\n",
    "    for feature in super_feature[\"sub_features\"]:\n",
    "        prompt = get_prompt(\n",
    "            feature[\"sub_feature\"], \n",
    "            feature[\"description\"],\n",
    "            super_feature[\"feature\"],\n",
    "            super_feature[\"description\"]\n",
    "        )\n",
    "\n",
    "        response = chat(model=evaluator_model, messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt,\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            },\n",
    "        ])\n",
    "\n",
    "        first_level_eval.append({\n",
    "            \"super_feature\": super_feature[\"feature\"],\n",
    "            \"super_feature_description\": super_feature[\"description\"],\n",
    "            \"feature\": feature[\"sub_feature\"],\n",
    "            \"description\": feature[\"description\"],\n",
    "            \"feature_eval\": json.loads((response[\"message\"][\"content\"]).replace('```', '').replace('json', ''))\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar os resultados em um arquivo JSON\n",
    "with open(f\"../data/deepseek/{prompt_technique}/first_level_eval.json\", \"w\") as f:\n",
    "    json.dump(first_level_eval, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Level 2 Feature Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_level_eval = []\n",
    "\n",
    "for super_feature in second_level_subfeatures:\n",
    "    for feature in super_feature[\"sub_features\"]:\n",
    "        prompt = get_prompt(\n",
    "            feature[\"sub_feature\"], \n",
    "            feature[\"description\"],\n",
    "            super_feature[\"feature\"],\n",
    "            super_feature[\"description\"]\n",
    "        )\n",
    "\n",
    "        response = chat(model=evaluator_model, messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt,\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            },\n",
    "        ])\n",
    "\n",
    "        second_level_eval.append({\n",
    "            \"root_feture\": super_feature[\"super_feature\"],\n",
    "            \"root_feature_description\": super_feature[\"super_feature_description\"],\n",
    "            \"super_feature\": super_feature[\"feature\"],\n",
    "            \"super_feature_description\": super_feature[\"description\"],\n",
    "            \"feature\": feature[\"sub_feature\"],\n",
    "            \"description\": feature[\"description\"],\n",
    "            \"feature_eval\": json.loads((response[\"message\"][\"content\"]).replace('```', '').replace('json', ''))\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar os resultados em um arquivo JSON\n",
    "with open(f\"../data/deepseek/{prompt_technique}/second_level_eval.json\", \"w\") as f:\n",
    "    json.dump(second_level_eval, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
