{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "from google.genai import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "gemini_api_key = os.getenv(\"GEMINI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = genai.Client(api_key=gemini_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'gemini'\n",
    "prompt_technique = 'base'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"../data/{model}/{prompt_technique}_prompt/first_level_subfeatures.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    first_level_subfeatures = json.load(file)\n",
    "\n",
    "with open(f\"../data/{model}/{prompt_technique}_prompt/second_level_subfeatures.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    second_level_subfeatures = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evalution Criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"../data/eval_criteria.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    eval_criteria = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sub-feature'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_criteria[\"super_feature_relation\"][0][\"rating\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A feature that is subordinated to the root feature.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_criteria[\"super_feature_relation\"][0][\"description\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are an expert in mobile app development and requirements engineering. \n",
    "Your primary role is to evaluate the refinement of software features, ensuring that the breakdown of high-level features into sub-features is logical, clear, relevant, and technically feasible.\n",
    "\n",
    "You will assess the decomposition based on the following criteria:\n",
    "\n",
    "1. **Feature Relationship Classification**:\n",
    "   - Classify each sub-feature in relation to the root feature using one of the following:\n",
    "     - **Sub-feature**: A feature that is directly derived from and dependent on the root feature.\n",
    "     - **Sibling feature**: A feature at the same hierarchical level as the root feature.\n",
    "     - **Super feature**: A feature that is broader or encompasses the root feature.\n",
    "     - **Identical feature**: A feature that is essentially the same as the root feature.\n",
    "     - **Other**: A feature that does not fit into the above categories.\n",
    "\n",
    "2. **Relevance (Rating: 1 to 5)**:\n",
    "   - Evaluate how relevant the sub-feature is to the root feature:\n",
    "     - 5: Highly relevant and a natural extension.\n",
    "     - 4: Mostly relevant and logically connected.\n",
    "     - 3: Moderately relevant but might not serve the same purpose.\n",
    "     - 2: Somewhat relevant, mainly because it belongs to the same app category.\n",
    "     - 1: Not relevant at all.\n",
    "\n",
    "3. **Clarity (Rating: 1 to 5)**:\n",
    "   - Assess the clarity and understandability of the sub-feature description:\n",
    "     - 5: Very clear and easily understandable.\n",
    "     - 4: Mostly clear with minor syntax issues.\n",
    "     - 3: Somewhat clear but contains ambiguities or is too lengthy.\n",
    "     - 2: Mostly unclear and difficult to understand.\n",
    "     - 1: Very unclear or irrelevant.\n",
    "\n",
    "4. **Feasibility (Rating: 1 to 5)**:\n",
    "   - Evaluate how practical and implementable the sub-feature is:\n",
    "     - 5: Feasible and commonly implemented in existing apps.\n",
    "     - 4: Feasible but lacks clear real-world examples.\n",
    "     - 3: Probably feasible but has some uncertainties.\n",
    "     - 2: Probably not feasible due to technical limitations.\n",
    "     - 1: Not feasible at all.\n",
    "\n",
    "**Instructions**:\n",
    "- Provide a structured evaluation for each sub-feature.\n",
    "- Use the above criteria to classify and rate the sub-feature.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt(feature: str, feature_description: str, super_feature: str, super_feature_description: str,) -> str:\n",
    "    return f\"\"\"\n",
    "Given the following mobile app feature and its refined sub-feature, evaluate the sub-feature based on the provided system guidelines.\n",
    "\n",
    "**Feature**\n",
    "```\n",
    "feature: {super_feature}\n",
    "description: {super_feature_description}\n",
    "```\n",
    "\n",
    "**Sub-feature to Evaluate**\n",
    "```\n",
    "sub_feature: {feature}\n",
    "description: {feature_description}\n",
    "```\n",
    "\n",
    "Provide a structured evaluation of this sub-feature, based on provided criteria.\n",
    "\n",
    "Return the evaluation as a structured JSON object in the following format:\n",
    "{{\n",
    "    \"relationship\": \"Sub-feature | Sibling feature | Super feature | Identical feature | Other\",\n",
    "    \"relevance\": Rating (1-5),\n",
    "    \"clarity\": Rating (1-5),\n",
    "    \"feasibility\": Rating (1-5)\n",
    "}}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Level 1 Feature Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'feature': 'Driver Guardian',\n",
       "  'description': \"Integrates with wearable devices to monitor the driver's vital signs, fatigue, and stress levels, providing recommendations for breaks or even assuming control of the vehicle if abnormal health patterns are detected.\",\n",
       "  'sub_features': [{'sub-feature': 'Wearable Device Integration & Pairing',\n",
       "    'description': 'Enables secure and reliable connection with compatible wearable devices (e.g., smartwatches, fitness trackers) via Bluetooth or other protocols.  Handles device discovery, pairing, and data stream configuration. Includes support for managing multiple paired devices and user authentication for secure data transmission.'},\n",
       "   {'sub-feature': 'Real-time Vital Sign Monitoring & Analysis',\n",
       "    'description': 'Collects and analyzes real-time data from the wearable device, including heart rate, heart rate variability (HRV), sleep patterns, and potentially other relevant biometrics (e.g., skin temperature, galvanic skin response).  Applies algorithms to detect fatigue, stress, and other abnormal health patterns based on established thresholds and personalized baselines. Incorporates noise filtering and data smoothing techniques for accurate readings.'},\n",
       "   {'sub-feature': 'Alerting & Recommendation System',\n",
       "    'description': 'Provides timely alerts and recommendations to the driver based on the analyzed vital signs. Alerts can be visual, auditory, or haptic. Recommendations may include suggestions to take a break, adjust driving posture, or pull over to rest. Alert escalation logic implemented based on severity and duration of abnormal patterns (e.g., warning -> urgent -> critical). Includes configurable alert thresholds and snooze functionality.'},\n",
       "   {'sub-feature': 'Automated Vehicle Control (Conditional)',\n",
       "    'description': \"Under pre-defined critical conditions (e.g., driver unconsciousness, severe fatigue leading to erratic driving), the app can trigger a safe vehicle control takeover.  This feature requires integration with the vehicle's ADAS (Advanced Driver-Assistance Systems) and may involve gradually slowing down the vehicle and bringing it to a controlled stop on the roadside. The implementation MUST prioritize safety and follow strict fail-safe protocols.  This functionality is conditional and dependent on vehicle capabilities and regulatory approval.\"},\n",
       "   {'sub-feature': 'Data Logging, Reporting & History',\n",
       "    'description': 'Records and stores historical vital sign data, driving events, and alert occurrences. Generates reports on driver health trends, fatigue patterns, and driving performance. Allows drivers and authorized personnel (e.g., fleet managers) to access and review historical data. Includes options for data export and integration with other health and safety management systems. Data privacy and security considerations are paramount.'}]}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Para teste sobre menos sub-fetures\n",
    "# first_level_subfeatures = [first_level_subfeatures[10]]\n",
    "# first_level_subfeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_level_eval = []\n",
    "\n",
    "for super_feature in first_level_subfeatures:\n",
    "    for feature in super_feature[\"sub_features\"]:\n",
    "        prompt = get_prompt(\n",
    "            feature[\"sub-feature\"], \n",
    "            feature[\"description\"],\n",
    "            super_feature[\"feature\"],\n",
    "            super_feature[\"description\"]\n",
    "        )\n",
    "\n",
    "        response = client.models.generate_content(\n",
    "            model=\"gemini-2.0-flash\",\n",
    "            config=types.GenerateContentConfig(system_instruction=system_prompt),\n",
    "            contents=prompt\n",
    "        )\n",
    "\n",
    "        first_level_eval.append({\n",
    "            \"super_feature\": super_feature[\"feature\"],\n",
    "            \"super_feature_description\": super_feature[\"description\"],\n",
    "            \"feature\": feature[\"sub-feature\"],\n",
    "            \"description\": feature[\"description\"],\n",
    "            \"feature_eval\": json.loads((response.text).replace('```', '').replace('json', ''))\n",
    "        })\n",
    "\n",
    "        time.sleep(5)\n",
    "\n",
    "# Salvar os resultados em um arquivo JSON\n",
    "with open(\"../data/gemini/base_prompt/first_level_eval.json\", \"w\") as f:\n",
    "    json.dump(first_level_eval, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Level 2 Feature Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'super_feature': 'Laugh evaluation',\n",
       "  'super_feature_description': 'The feature continually tracks the laughs of a user to count its quantity and assesses its authenticity, emotional context, and overall impact on social interactions.',\n",
       "  'feature': 'Laugh Detection & Counting',\n",
       "  'description': 'Utilizes microphone input and audio processing algorithms to detect and count instances of laughter from the user. Differentiates laughter from other sounds based on frequency, rhythm, and intensity.',\n",
       "  'siblings': ['Laugh Detection & Counting',\n",
       "   'Authenticity Assessment',\n",
       "   'Emotional Context Inference',\n",
       "   'Social Interaction Impact Analysis',\n",
       "   'Laughter Data Visualization & Insights'],\n",
       "  'sub_features': [{'sub-feature': 'Microphone Input Acquisition',\n",
       "    'description': \"Captures audio data from the user's microphone as the primary input source for laugh detection.\"},\n",
       "   {'sub-feature': 'Audio Preprocessing',\n",
       "    'description': 'Filters and cleans the audio data to remove noise and improve the accuracy of laugh detection algorithms.'},\n",
       "   {'sub-feature': 'Laughter Pattern Recognition',\n",
       "    'description': 'Identifies laughter instances by analyzing audio characteristics such as frequency, rhythm, intensity, and duration.'},\n",
       "   {'sub-feature': 'Sound Differentiation',\n",
       "    'description': 'Distinguishes laughter from other similar sounds like coughs or speech through advanced sound analysis and machine learning techniques.'},\n",
       "   {'sub-feature': 'Laughter Instance Counting',\n",
       "    'description': 'Accurately counts each detected instance of laughter and tracks its duration, and stores it for further analysis and evaluation.'}]}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Para teste sobre menos sub-fetures\n",
    "# second_level_subfeatures = [second_level_subfeatures[55]]\n",
    "# second_level_subfeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_level_eval = []\n",
    "\n",
    "for super_feature in second_level_subfeatures:\n",
    "    for feature in super_feature[\"sub_features\"]:\n",
    "        prompt = get_prompt(\n",
    "            feature[\"sub-feature\"], \n",
    "            feature[\"description\"],\n",
    "            super_feature[\"feature\"],\n",
    "            super_feature[\"description\"]\n",
    "        )\n",
    "\n",
    "        response = client.models.generate_content(\n",
    "            model=\"gemini-2.0-flash\",\n",
    "            config=types.GenerateContentConfig(system_instruction=system_prompt),\n",
    "            contents=prompt\n",
    "        )\n",
    "\n",
    "        second_level_eval.append({\n",
    "            \"root_feture\": super_feature[\"super_feature\"],\n",
    "            \"root_feature_description\": super_feature[\"super_feature_description\"],\n",
    "            \"super_feature\": super_feature[\"feature\"],\n",
    "            \"super_feature_description\": super_feature[\"description\"],\n",
    "            \"feature\": feature[\"sub-feature\"],\n",
    "            \"description\": feature[\"description\"],\n",
    "            \"feature_eval\": json.loads((response.text).replace('```', '').replace('json', ''))\n",
    "        })\n",
    "\n",
    "        time.sleep(5)\n",
    "\n",
    "# Salvar os resultados em um arquivo JSON\n",
    "with open(\"../data/gemini/base_prompt/second_level_eval.json\", \"w\") as f:\n",
    "    json.dump(second_level_eval, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
